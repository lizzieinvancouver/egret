---
title: "Modeling workflow"
author: "Victor Van der Meersch"
date: "April 2025"
date-format: "MMMM YYYY"
toc: true
number-sections: true
highlight: pygments
execute:
  enabled: true
format:
  html:
    html-math-method: katex
    theme:
      - lux
    embed-resources: true
    code-overflow: wrap
    linkcolor: "#B97C7C"
    page-layout: full
    fig-width: 8
    fig-height: 10
  pdf:
    keep-tex: true
    fig-width: 5.5
    fig-height: 5.5
    code-overflow: wrap
    monofontoptions:
      - Scale=0.5
knitr:
  opts_chunk:
    comment: ''
  opts_knit:
    global.par: TRUE
format-links: false
---

```{=html}
<!--
Options above come from Mike Betancourt's quarto template
-->
```

```{r}
library(ape)
library(geiger)
library(phytools)
require(rstan)
library(future)
library(future.apply)

kippenberger <- c("#8B174DFF", "#AE2565FF", "#C1447EFF", "#D06C9BFF", "#DA9FB8FF",
                  "#ADBE7CFF", "#8BA749FF", "#6E8537FF", "#4F5F28FF", "#343D1FFF")

```




## Conceptual analysis

As a first step, I think the main question we're trying to answer is:\
➡️ **What are the germination responses to different cues?** (<a href="https://github.com/lizzieinvancouver/egret/wiki/Questions">GitHub repo wiki</a>)

To answer this question, a systematic review of the scientific literature was conducted, focusing on controlled germination trials. They discarded:

-   studies on crops ( with likely altered traits because of active anthropogenic selection)\
-   studies conducted in the field (not fully controlled environments)\
-   studies with treatments not clearly distinguishable\
-   ... and other criteria I don't know about ...

To begin with, we focus solely on the effects of chilling (stratification) and forcing on germination.  


## Model building

### Simulate seed counts

The data generating process is, by nature, binomial: starting from a known number of seeds, we observe the number of successes (seeds that germinate).  
Let's simulate some data! We assume that species are related through a given phylogenetic tree.  
The following code is largely inspired (= copied without any shame) from Deirdre's amazing work for OSPREE.




```{r}
nspecies <- 40 # let's say we have 40 species 
spetree <- pbtree(n=nspecies, nsim=1, b=1, complete=FALSE,scale=1)
spetree$tip.label <- paste("s", 1:nspecies, sep="")

palette <- colorRampPalette(kippenberger)(nspecies)

```




For convenience, we create a function to simulate from a binomial distribution. We consider only one covariate.




```{r}
#| fig-height: 20

simulate_data_improved <- function(spetree){
  
  # parameters
  params <- list(a_z = rnorm(1,0,1.5), # root value intercept
                 lambda_a = rbeta(1,1.5,1.5), # lambda intercept
                 sigma_a = abs(rnorm(1,0,1)), # rate of evolution intercept
                 b_z = rnorm(1,0.5,1), # root value trait1 slope
                 lambda_b = rbeta(1,1.5,1.5), # lambda trait1
                 sigma_b = abs(rnorm(1,0,1)) # rate of evolution trait1
  )
  
  ## Simulate some data ## 
  # phylogenetic structure
  scaledtree_intercept <- rescale(spetree, model = "lambda", params$lambda_a)         
  params$intercepts <- fastBM(scaledtree_intercept,
                              a = params$a_z, mu = 0, 
                              sig2 = params$sigma_a ^ 2)
  scaledtree_slope <- rescale(spetree, model = "lambda", params$lambda_b)         
  params$slopes <- fastBM(scaledtree_slope, 
                          a = params$b_z, mu = 0, 
                          sig2 = params$sigma_b ^ 2)
  
  # We consider that a study looks only  at one species
  # and that a species might be considered by several studies
  nstudies_perspecies <- round(runif(nspecies, 1, 3)) # no. of different studies per species
  nstudies <- sum(nstudies_perspecies) # total number of studies
  species_study <- rep(1:nspecies, times = nstudies_perspecies) # species id considered by each study
  ntreat_perstudies <- round(runif(nstudies, 2, 6)) # no. of different treatments applied per study
  nexps <- sum(ntreat_perstudies) # total no. of experiments (i.e. studies*treatments)
  ntrialseeds_perexp <- round(runif(nexps, 10, 100)) # no. of seeds per experiments
  studies <- rep(1:nstudies, times = ntreat_perstudies)
  species <- rep(species_study, times = ntreat_perstudies) # species id per experiments
  
  # experimental observations
  x <- rnorm(n = nexps, mean = 0, sd = 1) # treatments applied
  yhat <- plogis(params$intercepts[species] + x * params$slopes[species], 
                 location = 0, scale = 1)
  y = rbinom(n = nexps, size = ntrialseeds_perexp, prob = yhat)
  
  return(list(
    params = lapply(params,round,2), 
    data = data.frame(species, studies, nseeds = ntrialseeds_perexp, x, y),
    vphy = vcv(spetree, corr = TRUE)))
  
}

```




We can then easily simulate many different datasets! And plot them.




```{r}
#| fig-width: 10
#| fig-height: 15

nsets <- 50
simulated_data <- lapply(1:nsets, function(i){
  simulate_data_improved(spetree)
})

par(mfrow = c(10,5), mar=c(1,0,1,0)+1)
for(i in 1:nsets){
  
  plot.new()
  plot.window(xlim = c(-3,3), ylim = c(0,max(simulated_data[[i]]$data$y)))
  grid()
  points(x = simulated_data[[i]]$data$x, y =  simulated_data[[i]]$data$y, 
         pch = 19, cex = 0.2,
         col = palette[simulated_data[[i]]$data$sp])
  axis(1, las = 1, cex.axis = 0.7, tck=-0.02, labels=FALSE)
  axis(2, las = 2, cex.axis = 0.7, tck=-0.02, labels=FALSE)
  title(paste0("a_z=", simulated_data[[i]]$params$a_z, ", l_a=", simulated_data[[i]]$params$lambda_a, ", s_a=", simulated_data[[i]]$params$sigma_a, "\n",
               "b_z=", simulated_data[[i]]$params$b_z, ", l_b=", simulated_data[[i]]$params$lambda_b, ", s_b=", simulated_data[[i]]$params$sigma_b), 
        adj=0, cex.main = 1)
  
  
}

```




### Binomial likelihood

In an ideal situation, we would always have the total number of seeds (number of trials) that each study is using.  
We could then use a binomial likelihood.

```stan
data {
  
  int<lower=1> N;
  int<lower=1> Nsp;
  int<lower=1, upper=Nsp> sp[N];
  int<lower=1> Ntrials[N];
  int<lower=0> y[N]; // response, number of successes!
  vector[N] x; // predictor
  corr_matrix[Nsp] Vphy; // phylogenetic relationship matrix (fixed)
  
}

parameters {
  
  // intercept (+ the portion of phenotypes, not predicted by x, which still covary between related species, right?)
  vector[Nsp] a; 
  real a_z; // root value
  real<lower=0, upper=1> lambda_a; // phylogenetic structure      
  real<lower=0> sigma_a; // overall rate of change (brownian motion?)
  
  // slope of x effect
  vector[Nsp] b; 
  real b_z; // root value
  real<lower=0, upper=1> lambda_b;  // phylogenetic structure        
  real<lower=0> sigma_b; // overall rate of change (brownian motion?)
  
}

transformed parameters{
  
  corr_matrix[Nsp] C_a = lambda_a * Vphy;
  C_a = C_a - diag_matrix(diagonal(C_a)) + diag_matrix(diagonal(Vphy));
  
  corr_matrix[Nsp] C_b = lambda_b * Vphy;
  C_b = C_b - diag_matrix(diagonal(C_b)) + diag_matrix(diagonal(Vphy));
  
  // more numerically stable and more efficient to use pre-factored covariance matrices (i.e. multi_normal_cholesky in the following
  matrix[Nsp,Nsp] L_a = cholesky_decompose(sigma_a^2*C_a);
  matrix[Nsp,Nsp] L_b =  cholesky_decompose(sigma_b^2*C_b);
  real<lower=0, upper = 1> mu[N];
                                                                                         
  for(i in 1:N){
    mu[i] = inv_logit(a[sp[i]] + b[sp[i]] * x[i]);
  }
                                                                                         
}

model {
  
  a ~ multi_normal_cholesky(rep_vector(a_z,Nsp), L_a); 
  b ~ multi_normal_cholesky(rep_vector(b_z,Nsp), L_b); 
  
  // y ~ beta(shape_alpha, shape_beta);
  y ~ binomial(Ntrials, mu);
  
  // priors 
  a_z ~ normal(0, 1.5); 
  b_z ~ normal(0.5, 1); 
  
  lambda_a ~ beta(1.5, 1.5);
  sigma_a ~ normal(0, 1);
  
  lambda_b ~ beta(1.5, 1.5);
  sigma_b ~ normal(0, 1);
  
}
```

### Beta likelihood

But we rarely have the initial number of seeds, so we will need to use _percentage of germination_ rather than number of successes/number of trials.  
So we will likely need a Beta likelihood. As the support of a Beta distribution does not include 0 and 1, we implement a ordered Beta regression (following <a href="https://doi.org/10.1017/pan.2022.20">R. Kubinec work</a>):

```stan
// Beta regression with proportion and degenerate responses (i.e. 0 and 1)
// Original code from R. Kubinec, https://github.com/saudiwin/ordbetareg

functions {
  
  // prior from Michael Betancourt for ordered cutpoints
  // see: https://betanalpha.github.io/assets/case_studies/ordinal_regression.html
    real induced_dirichlet_lpdf(vector c, vector alpha, real phi) {
    int K = num_elements(c) + 1;
    vector[K - 1] sigma = inv_logit(phi - c);
    vector[K] p;
    matrix[K, K] J = rep_matrix(0, K, K);
    
    // Induced ordinal probabilities
    p[1] = 1 - sigma[1];
    for (k in 2:(K - 1))
      p[k] = sigma[k - 1] - sigma[k];
    p[K] = sigma[K - 1];
    
    // Baseline column of Jacobian
    for (k in 1:K) J[k, 1] = 1;
    
    // Diagonal entries of Jacobian
    for (k in 2:K) {
      real rho = sigma[k - 1] * (1 - sigma[k - 1]);
      J[k, k] = - rho;
      J[k - 1, k] = rho;
    }
    
    return   dirichlet_lpdf(p | alpha)
           + log_determinant(J);
  }
}

data {
  
  int<lower=0> N_prop; // number of proportion observations (0,1)
  int<lower=0> N_degen; // number of 0/1 observations
  
  int<lower=1> Nsp; // number of species
  int<lower=1, upper=Nsp> sp_prop[N_prop]; // species ID for prop. observations
  int<lower=1, upper=Nsp> sp_degen[N_degen]; // species ID for degen. observations
  
  vector[N_prop] y_prop; // Y in (0,1)
  int<lower=0,upper = 1> y_degen[N_degen]; // Y in {0,1}
  
  vector[N_prop] x_prop; // covariate X for proportion outcome
  vector[N_degen] x_degen; // covariate X for degenerate (0,1) outcome
  
  corr_matrix[Nsp] Vphy; // phylogenetic relationship matrix (fixed)
}

parameters {
  
  // intercept (+ the portion of phenotypes, not predicted by x, which still covary between related species, right?)
  vector[Nsp] a; 
  real a_z; // root value
  real<lower=0, upper=1> lambda_a; // phylogenetic structure      
  real<lower=0> sigma_a; // overall rate of change (brownian motion?)
  
  // slope of x effect
  vector[Nsp] b; 
  real b_z; // root value
  real<lower=0, upper=1> lambda_b;  // phylogenetic structure        
  real<lower=0> sigma_b; // overall rate of change (brownian motion?)
  
  ordered[2] cutpoints; // cutpoints on ordered (latent) variable (also stand in as intercepts)
  real<lower=0> kappa; // scale parameter for beta regression
}

transformed parameters {
  
  corr_matrix[Nsp] C_a = lambda_a * Vphy;
  C_a = C_a - diag_matrix(diagonal(C_a)) + diag_matrix(diagonal(Vphy));
  
  corr_matrix[Nsp] C_b = lambda_b * Vphy;
  C_b = C_b - diag_matrix(diagonal(C_b)) + diag_matrix(diagonal(Vphy));
  
  // more numerically stable and more efficient to use pre-factored covariance matrices (i.e. multi_normal_cholesky in the following
  matrix[Nsp,Nsp] L_a = cholesky_decompose(sigma_a^2*C_a);
  matrix[Nsp,Nsp] L_b =  cholesky_decompose(sigma_b^2*C_b); 
  
  real calc_degen[N_degen];
  real calc_prop[N_prop];
  
  if(N_degen>0) {
    for(i in 1:N_degen){
      calc_degen[i] = a[sp_degen[i]] + b[sp_degen[i]] * x_degen[i];
    }
  }
  
  for(i in 1:N_prop){
    
    calc_prop[i] = a[sp_prop[i]] + b[sp_prop[i]] * x_prop[i];
    
  }

}
model {
  
  a ~ multi_normal_cholesky(rep_vector(a_z,Nsp), L_a); 
  b ~ multi_normal_cholesky(rep_vector(b_z,Nsp), L_b); 
  
  target += induced_dirichlet_lpdf(cutpoints | rep_vector(1, 3), 0);
  
  // need separate loops for logit (0/1) and beta regression
  if(N_degen>0) {
    for(n in 1:N_degen) {
      if(y_degen[n]==0) {
        // Pr(Y==0)
        target += log1m_inv_logit(calc_degen[n] - cutpoints[1]);
      } else {
        //Pr(Y==1)
        target += log_inv_logit(calc_degen[n] - cutpoints[2]);
      }
    }
  }
  
  for(n in 1:N_prop) {
    // Pr(Y in (0,1))
    target += log(inv_logit(calc_prop[n] - cutpoints[1]) - inv_logit(calc_prop[n] - cutpoints[2]));
    // Pr(Y==x where x in (0,1))
    y_prop[n] ~ beta_proportion(inv_logit(calc_prop[n]),kappa);
  }
  
  // priors
  a_z ~ normal(0, 1.5); 
  b_z ~ normal(0.5, 1); 
  
  lambda_a ~ beta(1.5, 1.5);
  sigma_a ~ normal(0, 1);
  
  lambda_b ~ beta(1.5, 1.5);
  sigma_b ~ normal(0, 1);
  
  kappa ~ exponential(.1); // vague?
  
}
```

### Compare both models

Let's fit both models on the simulated datasets.




```{r}

get_estimates <- function(summ){
  return(
    data.frame(lambda_a.mean = summ["lambda_a" , "mean"],
             lambda_a.q2.5 = summ["lambda_a" , "X2.5."],
             lambda_a.q97.5  = summ["lambda_a" , "X97.5."],
             sigma_a.mean = summ["sigma_a" , "mean"],
             sigma_a.q2.5 = summ["sigma_a" , "X2.5."],
             sigma_a.q97.5  = summ["sigma_a" , "X97.5."],
             lambda_b.mean = summ["lambda_b" , "mean"],
             lambda_b.q2.5 = summ["lambda_b" , "X2.5."],
             lambda_b.q97.5  = summ["lambda_b" , "X97.5."],
             sigma_b.mean = summ["sigma_b" , "mean"],
             sigma_b.q2.5 = summ["sigma_b" , "X2.5."],
             sigma_b.q97.5  = summ["sigma_b" , "X97.5."],
             slopes.mean = summ[paste0("b[", 1:nspecies, "]"), "mean"],
             slopes.q2.5 = summ[paste0("b[", 1:nspecies, "]"), "X2.5."],
             slopes.q97.5 = summ[paste0("b[", 1:nspecies, "]"), "X97.5."],
             intercepts.mean = summ[paste0("a[", 1:nspecies, "]"), "mean"],
             intercepts.q2.5 = summ[paste0("a[", 1:nspecies, "]"), "X2.5."],
             intercepts.q97.5 = summ[paste0("a[", 1:nspecies, "]"), "X97.5."],
             a_z.mean = summ["a_z", "mean"],
             a_z.q2.5 = summ["a_z", "X2.5."],
             a_z.q97.5 = summ["a_z", "X97.5."],
             b_z.mean = summ["b_z", "mean"],
             b_z.q2.5 = summ["b_z", "X2.5."],
             b_z.q97.5 = summ["b_z", "X97.5."]))
}


run_models <- TRUE

# fit models
if(run_models){
  
  smbin <- stan_model("../stan/binomiallikelihood.stan")
  plan(multisession, workers = 4) # here we use 4x4 = 16 cores (i.e. nested parallelization)
  databin <- future_lapply(simulated_data, function(simulated){
      
      mdl.data <- list(y = simulated$data$y,
                       N = nrow(simulated$data),
                       Nsp = nspecies,
                       sp = simulated$data$species,
                       x = simulated$data$x,
                       Ntrials = simulated$data$nseeds,
                       Vphy= simulated$vphy)
    
      fit <- sampling(smbin, mdl.data, 
                      iter = 4000, warmup = 3000,
                      chains = 4, cores = 4)
      
      summ <- data.frame(summary(fit)[["summary"]])
      
      sampler_params  <- get_sampler_params(fit, inc_warmup = FALSE)
      diagnostics <- list(
        max_treedepth= max(sapply(sampler_params, function(x) max(x[, "treedepth__"]))),
        max_divergence = max(sapply(sampler_params, function(x) sum(x[, "divergent__"]))),
        max_rhat = max(summ$Rhat, na.rm = TRUE),
        min_ess = min(summ$n_eff, na.rm = TRUE)
      )
      
      estimates <- get_estimates(summ)
      
      posteriors <- c(extract(fit, pars = c("lambda_a", "lambda_b")), chain = list(rep(1:4, each = 1000)), limits = list(c(0,1)))
      
      return(list(sim = simulated$data, 
                  est = estimates,
                  post = posteriors,
                  par = simulated$params,
                  diag = diagnostics))
    }, future.seed=TRUE)
  plan(sequential);gc()
  saveRDS(databin, file = "modeling/output/comparison/bionomiallikelihood.rds")
  
  smordbeta <- stan_model("../stan/orderedbetalikelihood.stan")
  plan(multisession, workers = 4) 
  databeta <- future_lapply(simulated_data, function(simulated){
      
      simulated$data$yperc <- simulated$data$y/simulated$data$nseeds
      
      mdl.data <- list(N_degen=sum(simulated$data$yperc %in% c(0,1)),
                       N_prop=sum(simulated$data$yperc>0 & simulated$data$yperc<1),
                       
                       Nsp = nspecies,
                       sp_degen = array(simulated$data$species[simulated$data$yperc %in% c(0,1)],
                                        dim = sum(simulated$data$yperc %in% c(0,1))),
                       sp_prop = simulated$data$species[simulated$data$yperc>0 & simulated$data$yperc<1],
                       
                       
                       y_degen=array(simulated$data$yperc[simulated$data$yperc %in% c(0,1)],
                                     dim = sum(simulated$data$yperc %in% c(0,1))),
                       y_prop=simulated$data$yperc[simulated$data$yperc>0 & simulated$data$yperc<1],
                       
                       x_degen=array(simulated$data$x[simulated$data$yperc %in% c(0,1)],
                                     dim = sum(simulated$data$yperc %in% c(0,1))),
                       x_prop=simulated$data$x[simulated$data$yperc>0 & simulated$data$yperc<1],
                       
                       Vphy= simulated$vphy)
      
      fit <- sampling(smordbeta, mdl.data, 
                      iter = 4000, warmup = 3000,
                      chains = 4, cores = 4)
      
      summ <- data.frame(summary(fit)[["summary"]])
      
      sampler_params  <- get_sampler_params(fit, inc_warmup = FALSE)
      diagnostics <- list(
        max_treedepth= max(sapply(sampler_params, function(x) max(x[, "treedepth__"]))),
        max_divergence = max(sapply(sampler_params, function(x) sum(x[, "divergent__"]))),
        max_rhat = max(summ$Rhat, na.rm = TRUE),
        min_ess = min(summ$n_eff, na.rm = TRUE)
      )
      
      estimates <- get_estimates(summ)
      
      posteriors <- c(extract(fit, pars = c("lambda_a", "lambda_b")), chain = list(rep(1:4, each = 1000)), limits = list(c(0,1)))
      
      return(list(sim = simulated$data, 
                  est = estimates,
                  post = posteriors,
                  par = simulated$params,
                  diag = diagnostics))
    }, future.seed=TRUE)
  plan(sequential);gc()
  saveRDS(databeta, file = "modeling/output/comparison/betalikelihood.rds")
}else{
  databin <- readRDS(file = "modeling/output/comparison/bionomiallikelihood.rds")
  databeta <- readRDS(file = "modeling/output/comparison/betalikelihood.rds")
}

```

